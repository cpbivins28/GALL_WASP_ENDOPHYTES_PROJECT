---
title: "Gall_Project_NEATEST"
output: html_document
date: "2025-06-13"
---

---
title: "Gall_Project_NEATEST"
author: "Christopher Bivins"
date: "2024-09-30"
output: html_document
---

#### Packages
```{r}
install.packages("dunn.test")
install.packages("ggpubr")
install.packages("ggsignif")
install.packages("VennDiagram")
install.packages("reshape2")
install.packages("RColorBrewer")
install.packages("viridis")
install.packages("phyloseq")
```

```{r}
library(dunn.test)
library(gridExtra)
library(grid)
library(VennDiagram)
library(reshape2)
library(RColorBrewer)
library(phyloseq)
library(vegan)
library(FSA)
library(dplyr)
library(betapart)
library(indicspecies)
library(tibble)
library(DESeq2)
library(tidyr)
library(ggplot2)
```

```{r}
install.packages("tidyverse")
install.packages("vegan")
install.packages("iNEXT")
install.packages("FSA")
install.packages("phyloseq")
install.packages("reshape2")
install.packages("data.table")

# Install devtools (for GitHub installs)
install.packages("devtools")

# Install ggiNEXT from GitHub
devtools::install_github("JohnsonHsieh/iNEXT")

# (Optional Bioconductor safety net for phyloseq dependency resolution)
install.packages("BiocManager")
BiocManager::install("phyloseq")
```

```{r}
# Load necessary libraries
library(tidyverse)
library(phyloseq)
library(vegan)
library(FSA)
library(reshape2)
library(data.table)



## Data Preparation 

### Import the BIOM file that is the final output of AMPtk

```{r}
endophytes_physeq <- import_biom("/Users/christopherbivins/Desktop/AMPTK_Outputs/Endophytes_Project/taxonomyITS.biom")
# Extract OTU table as a data frame
otu_df <- as.data.frame(otu_table(endophytes_physeq))
```

### Check if any samples have all zero sequence counts for all OTUs
```{r}
# Extract the OTU table from endophytes_physeq
otu_table_endophytes <- otu_table(endophytes_physeq)

# Find samples with all zero counts
zero_count_samples <- colnames(otu_table_endophytes)[colSums(otu_table_endophytes) == 0]

# Print the results
if (length(zero_count_samples) > 0) {
  cat("Samples with all zero counts:\n")
  print(zero_count_samples)
} else {
  cat("No samples with all zero counts found.\n")
}

```

#### Sample O1-G-5-S164-L001 has no sequence counts for any OTU whatsoever. This is a problem

### Perform negative control filtering 
(Note: For now, I am just going to rely on my PCR negative control. I have three other negative controls that I will come back to when I understand better what to do with them. One is a blank DNA extraction negative control, another is a blank tube that was put in the lyophilizer when I lyophilized the samples for this project, and the last negative control sample is from the buffer wash solution I used to surface sterilize leaves/galls)

```{r}
# Identify the negative control samples
neg_samples <- grep("NEG", colnames(otu_df), value = TRUE)
# Compute the total count of each OTU across the negative control samples
neg_counts <- rowSums(otu_df[neg_samples])
# Iterate over each OTU found in the negative controls
for (otu in names(neg_counts)) {
  # Check if the OTU is in the sample data
  if (otu %in% rownames(otu_df)) {
    # Subtract the negative control counts from the sample counts, ensuring no negative values
    otu_df[otu,] <- pmax(otu_df[otu,] - neg_counts[otu], 0)
  }
}
# Convert the adjusted DataFrame back to a phyloseq OTU table
otu_table_adj <- otu_table(otu_df, taxa_are_rows = TRUE)
# Create the new adjusted phyloseq object without phylogenetic tree
physeq_adj <- phyloseq(otu_table_adj, sample_data(endophytes_physeq), tax_table(endophytes_physeq))
# Change the name of physeq_adj to amptk_filtered_nc for downstream analysis
endophytes_amptk_filtered_nc <- physeq_adj
# Remove Negative Control Samples
# Define a vector of sample names to be removed
samples_to_remove <- c("NEG-CONTROL-N-S241-L001", "NEG-CONTROL-R-S242-L001", 
                       "BLANK-R-S243-L001", "WASH-JULY-S224-L001", "WASH-MAY-S223-L001", 
                       "WASH-SEP-S225-L001", "LYOPH-JULY-S221-L001", "LYOPH-MAY-S220-L001", 
                       "LYOPH-SEP-S222-L001")
# Reinitialize phyloseq object without negative control samples
endophytes_amptk_filtered_nc <- subset_samples(endophytes_amptk_filtered_nc, !sample_names(endophytes_amptk_filtered_nc) %in% samples_to_remove)
# Verify that the negative control filtering worked:
# Extract count for a specific OTU in a specific sample from the original physeq
otu_count_physeq <- otu_table(endophytes_physeq)["OTU5", "BOR-1-MAY-S25-L001"]
print(paste("Count in original physeq: ", otu_count_physeq))
# Extract count for the same OTU in the same sample from the adjusted physeq
otu_count_physeq_adj <- otu_table(endophytes_amptk_filtered_nc)["OTU5", "BOR-1-MAY-S25-L001"]
print(paste("Count in adjusted physeq: ", otu_count_physeq_adj))
# Convert the filtered Sample table to a data.frame
endophytes_filtered_sample_df <- as.data.frame(sample_data(endophytes_amptk_filtered_nc))

```

### Assign Functional/Ecological Guild Traits

```{r}
## Within the biom_data file, the "tax_table" that contains all the taxonomic information is incorrectly formated. The column names for different taxonomic levels are "Rank1", "Rank2", "Rank3", etc., when they really should be "kingdom", "phylum", "class", etc... I need to rename these columns appropriately so that the guild assignment step recognizes the required taxonomic headers. 
rank_names(endophytes_amptk_filtered_nc)
colnames(tax_table(endophytes_amptk_filtered_nc)) = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
rank_names(endophytes_amptk_filtered_nc)
# Clean up the names in the taxonomy table - get rid of all that junk!
tax_table(endophytes_amptk_filtered_nc)
tax_table(endophytes_amptk_filtered_nc)[, colnames(tax_table(endophytes_amptk_filtered_nc))] <- gsub(tax_table(endophytes_amptk_filtered_nc)[, colnames(tax_table(endophytes_amptk_filtered_nc))], pattern = "[a-z]__", replacement = "")
tax_table(endophytes_amptk_filtered_nc)
# Guild assignment function 
assign_guild <- function(object, database) { 
  ### This function assigns trophic modes (and other traits) to OTUs based on taxonomy
  # returning a table with taxonomy and guild/traits for each OTU 
  ### Arguments:
  # object: a phyloseq object, for example imported from a .biom file
  # database: Reference used, for example FungalTraits (Polme et al. 2020, Fungal Diversity 105, 1-16).
  ### Function:
  # load required packages 
  require(file2meco)
  require(microeco)
  # convert phyloseq object into a "microtable"
  meco <- phyloseq2meco(object)
  # verify that OTUs and samples information is consistent across files
  meco$tidy_dataset()
  # assign guilds
  t1 <- trans_func$new(dataset = meco)
  t1$for_what <- "fungi"
  t1$cal_spe_func(fungi_database = database)
  # create a dataframe with taxonomy and guild/traits information
  as.data.frame(t1$res_spe_func_raw_FungalTraits)
}
# Assign guilds to OTUs
# I'm getting an error message saying "Error in if (any(apply(otu_table, 1, sum) == 0)) { :
# I need to first investigate what values have either NA or NaN before I remove them (or change them to zeros), as will likely need to be done in order to assign guilds 
# Check for NA values in the OTU table
any(is.na(otu_table(endophytes_amptk_filtered_nc)))
# Convert the OTU table to a matrix
otu_matrix <- as.matrix(otu_table(endophytes_amptk_filtered_nc))
# Find the indices of NA values
na_indices <- which(is.na(otu_matrix), arr.ind = TRUE)
# Print the indices
print(na_indices)
# Ah, the Negative control samples (NEG1-4) have all been changed to NaN - we just need to convert these to zeroes
# Get the OTU table
otu_table <- otu_table(endophytes_amptk_filtered_nc)
# Replace NaN values with 0
otu_table[is.nan(otu_table)] <- 0
# Assign the modified otu_table back to the phyloseq object
otu_table(endophytes_amptk_filtered_nc) <- otu_table
# Assign guilds to the entire dataset
guild_table = assign_guild(object = endophytes_amptk_filtered_nc, database = "FungalTraits")

```

### Export guild table for plotting with other programs
```{r}
# Define the directory where you want to save the CSV file
output_directory <- "/Users/christopherbivins/Desktop/csv_files_for_galls_graphs/"

# Ensure the directory exists
if (!dir.exists(output_directory)) {
  dir.create(output_directory, recursive = TRUE)
}

# Define the file path for the guild table
guild_table_file_path <- file.path(output_directory, "guild_table.csv")

# Write the guild table to a CSV file
write.csv(guild_table, file = guild_table_file_path, row.names = TRUE)

# Print a message indicating the file was saved
cat("Guild table saved to:", guild_table_file_path, "\n")

```


### Subset out Gall samples

```{r}
# Define the sample name prefixes from gall project
galls_prefixes <- c("O1", "O2", "O3")
# Function to create a logical vector indicating which samples to keep based on prefixes
filter_samples_by_prefix <- function(sample_names, prefixes) {
  sapply(sample_names, function(name) any(sapply(prefixes, function(prefix) startsWith(name, prefix))))
}
# Subset samples for galls_project_physeq
galls_samples <- sample_names(endophytes_amptk_filtered_nc)[filter_samples_by_prefix(sample_names(endophytes_amptk_filtered_nc), galls_prefixes)]
galls_project_physeq <- prune_samples(galls_samples, endophytes_amptk_filtered_nc)
# Verify the subset
print(sample_names(galls_project_physeq))
```


```{r}

remove_r_samples <- function(physeq) {
  samples_to_keep <- sample_names(physeq)[!grepl("-R-", sample_names(physeq))]
  physeq_filtered <- prune_samples(samples_to_keep, physeq)
  return(physeq_filtered)
}
# Apply the function to galls_project_physeq
galls_project_physeq <- remove_r_samples(galls_project_physeq)
# Verify the results by printing the sample names
print(sample_names(galls_project_physeq))
```

### Print the number of OTUs that have a sequence count greater than 0 for every sample in galls_project_physeq
```{r}
# Extract the OTU table from galls_project_physeq
otu_table_galls <- otu_table(galls_project_physeq)

# Calculate the number of OTUs with sequence counts greater than 0 for each sample
num_non_zero_otus <- colSums(otu_table_galls > 0)

# Print the number of non-zero OTUs for each sample
cat("Number of OTUs with sequence counts greater than 0 for each sample:\n")
print(num_non_zero_otus)

```

### Add sample metadata and create a new phyloseq object. I have a file that contains metadata information for all samples in the following location:
/Users/christopherbivins/Desktop/Gall_project_metadata.csv
```{r}
metadata <- read.csv("/Users/cbivins/Desktop/Gall_project_metadata.csv", row.names = 1)
sample_data <- sample_data(metadata)

# Remove the existing Treatment column from the phyloseq object, if it exists
existing_data <- sample_data(galls_project_physeq)
existing_data$Treatment <- NULL
sample_data(galls_project_physeq) <- existing_data

# Now merge with the new metadata
galls_project_physeq_updated <- merge_phyloseq(galls_project_physeq, sample_data(metadata))



```

### Check to see if zero-count OTUs have zeroes or ones
```{r}
# Extract OTU counts for O1-G-5-S164-L001 from the original phyloseq object
original_counts_O1_G_5 <- otu_table(galls_project_physeq_updated)[, "O1-G-5-S164-L001"]
# Print the OTU counts for O1-G-5-S164-L001
cat("Original OTU counts for O1-G-5-S164-L001:\n")
print(original_counts_O1_G_5)
```


### Create data objects for future use. It will be useful to define the sample names for different sample-pairs. By sample pairs, I mean pairing each individual gall sample with the leaf that it came from. It will also be useful to define what samples are ungalled leaves

```{r}


# Define sample pairs for Cynips and Andricus galls
cynips_sample_pairs <- data.frame(
  SampleName_Gall = c("O1-CQ1-S205-L001", "O1-CQ2-S206-L001", "O1-CQ3-S207-L001", "O1-CQ4-S208-L001", "O1-CQ5-S209-L001",
                      "O2-CQ1-S210-L001", "O2-CQ2-S211-L001", "O2-CQ3-S212-L001", "O2-CQ4-S213-L001", "O2-CQ5-S214-L001",
                      "O3-CQ1-S215-L001", "O3-CQ2-S216-L001", "O3-CQ3-S217-L001", "O3-CQ4-S218-L001", "O3-CQ5-S219-L001"),
  SampleName_Leaf = c("O1-CQ1-GPOS-S175-L001", "O1-CQ2-GPOS-S176-L001", "O1-CQ3-GPOS-S177-L001", "O1-CQ4-GPOS-S178-L001", "O1-CQ5-GPOS-S179-L001",
                      "O2-CQ1-GPOS-S180-L001", "O2-CQ2-GPOS-S181-L001", "O2-CQ3-GPOS-S182-L001", "O2-CQ4-GPOS-S183-L001", "O2-CQ5-GPOS-S184-L001",
                      "O3-CQ1-GPOS-S185-L001", "O3-CQ2-GPOS-S186-L001", "O3-CQ3-GPOS-S187-L001", "O3-CQ4-GPOS-S188-L001", "O3-CQ5-GPOS-S189-L001")
)

andricus_sample_pairs <- data.frame(
  SampleName_Gall = c("O1-AG1-S190-L001", "O1-AG2-S191-L001", "O1-AG3-S192-L001", "O1-AG4-S193-L001", "O1-AG5-S194-L001",
                      "O2-AG1-S195-L001", "O2-AG2-S196-L001", "O2-AG3-S197-L001", "O2-AG4-S198-L001", "O2-AG5-S199-L001",
                      "O3-AG1-S200-L001", "O3-AG2-S201-L001", "O3-AG3-S202-L001", "O3-AG4-S203-L001"),
  SampleName_Leaf = c("O1-AG1-GPOS-S145-L001", "O1-AG2-GPOS-S146-L001", "O1-AG3-GPOS-S147-L001", "O1-AG4-GPOS-S148-L001", "O1-AG5-GPOS-S149-L001",
                      "O2-AG1-GPOS-S150-L001", "O2-AG2-GPOS-S151-L001", "O2-AG3-GPOS-S152-L001", "O2-AG4-GPOS-S153-L001", "O2-AG5-GPOS-S154-L001",
                      "O3-AG1-GPOS-S155-L001", "O3-AG2-GPOS-S156-L001", "O3-AG3-GPOS-S157-L001", "O3-AG4-GPOS-S158-L001")
)

# Define Cynips gall samples
cynips_galls_samples <- c("O1-CQ1-S205-L001", "O1-CQ2-S206-L001", "O1-CQ3-S207-L001", "O1-CQ4-S208-L001", "O1-CQ5-S209-L001",
                          "O2-CQ1-S210-L001", "O2-CQ2-S211-L001", "O2-CQ3-S212-L001", "O2-CQ4-S213-L001", "O2-CQ5-S214-L001",
                          "O3-CQ1-S215-L001", "O3-CQ2-S216-L001", "O3-CQ3-S217-L001", "O3-CQ4-S218-L001", "O3-CQ5-S219-L001")

# Define leaves galled by Cynips samples
leaves_galled_by_cynips_samples <- c("O1-CQ1-GPOS-S175-L001", "O1-CQ2-GPOS-S176-L001", "O1-CQ3-GPOS-S177-L001", "O1-CQ4-GPOS-S178-L001", "O1-CQ5-GPOS-S179-L001",
                                     "O2-CQ1-GPOS-S180-L001", "O2-CQ2-GPOS-S181-L001", "O2-CQ3-GPOS-S182-L001", "O2-CQ4-GPOS-S183-L001", "O2-CQ5-GPOS-S184-L001",
                                     "O3-CQ1-GPOS-S185-L001", "O3-CQ2-GPOS-S186-L001", "O3-CQ3-GPOS-S187-L001", "O3-CQ4-GPOS-S188-L001", "O3-CQ5-GPOS-S189-L001")

# Define Andricus gall samples
andricus_galls_samples <- c("O1-AG1-S190-L001", "O1-AG2-S191-L001", "O1-AG3-S192-L001", "O1-AG4-S193-L001", "O1-AG5-S194-L001",
                            "O2-AG1-S195-L001", "O2-AG2-S196-L001", "O2-AG3-S197-L001", "O2-AG4-S198-L001", "O2-AG5-S199-L001",
                            "O3-AG1-S200-L001", "O3-AG2-S201-L001", "O3-AG3-S202-L001", "O3-AG4-S203-L001")

# Define leaves galled by Andricus samples
leaves_galled_by_andricus_samples <- c("O1-AG1-GPOS-S145-L001", "O1-AG2-GPOS-S146-L001", "O1-AG3-GPOS-S147-L001", "O1-AG4-GPOS-S148-L001", "O1-AG5-GPOS-S149-L001",
                                       "O2-AG1-GPOS-S150-L001", "O2-AG2-GPOS-S151-L001", "O2-AG3-GPOS-S152-L001", "O2-AG4-GPOS-S153-L001", "O2-AG5-GPOS-S154-L001",
                                       "O3-AG1-GPOS-S155-L001", "O3-AG2-GPOS-S156-L001", "O3-AG3-GPOS-S157-L001", "O3-AG4-GPOS-S158-L001")


# Define ungalled leaf samples
ungalled_leaves <- c("O1-G-1-S160-L001", "O1-G-2-S161-L001", "O1-G-3-S162-L001", "O1-G-4-S163-L001", "O1-G-5-S164-L001",
                     "O2-G-1-S165-L001", "O2-G-2-S166-L001", "O2-G-3-S167-L001", "O2-G-4-S168-L001", "O2-G-5-S169-L001",
                     "O3-G-1-S170-L001", "O3-G-2-S171-L001", "O3-G-3-S172-L001", "O3-G-4-S173-L001", "O3-G-5-S174-L001")

# Presence/absence phyloseq object
# Function to convert OTU counts to presence/absence
make_presence_absence <- function(physeq_obj) {
  otu_table_binary <- otu_table(physeq_obj)
  
  # Convert OTU counts to binary presence/absence (1 if present, 0 if absent)
  otu_table_binary[otu_table_binary > 0] <- 1
  
  # Create a new phyloseq object with the transformed binary OTU table
  physeq_pa <- phyloseq(otu_table(otu_table_binary, taxa_are_rows = TRUE), 
                        sample_data(physeq_obj), 
                        tax_table(physeq_obj))
  
  return(physeq_pa)
}

# Create the presence/absence phyloseq object
PA_galls_project_physeq <- make_presence_absence(galls_project_physeq_updated)

# Create relative abundance phyloseq object
# Transform the OTU table to relative abundances
RA_galls_project_physeq <- transform_sample_counts(galls_project_physeq_updated, function(x) x / sum(x))

```

### Export presence/absence data as csv files (OTU table, Taxonomy Table)
```{r}
# Define the directory where you want to save the CSV files
output_directory <- "/Users/christopherbivins/Desktop/csv_files_for_galls_graphs/"

# Ensure the directory exists
if (!dir.exists(output_directory)) {
  dir.create(output_directory, recursive = TRUE)
}

# Extract the OTU table (already in presence/absence format)
otu_presence_absence <- as.data.frame(otu_table(PA_galls_project_physeq))
otu_presence_absence$OTU_ID <- rownames(otu_presence_absence)

# Extract the taxonomy table
taxonomy_table <- as.data.frame(tax_table(PA_galls_project_physeq))
taxonomy_table$OTU_ID <- rownames(taxonomy_table)

# Extract the sample data (metadata) table
sample_data_table <- as.data.frame(sample_data(PA_galls_project_physeq))

# Define file paths
otu_file_path <- file.path(output_directory, "OTU_presence_absence_table.csv")
taxonomy_file_path <- file.path(output_directory, "taxonomy_table.csv")
sample_data_file_path <- file.path(output_directory, "sample_data_table.csv")

# Write the OTU table to a CSV file
write.csv(otu_presence_absence, file = otu_file_path, row.names = FALSE)

# Write the taxonomy table to a CSV file
write.csv(taxonomy_table, file = taxonomy_file_path, row.names = FALSE)


# Print messages indicating the files were saved
cat("OTU presence/absence table saved to:", otu_file_path, "\n")
cat("Taxonomy table saved to:", taxonomy_file_path, "\n")


```


### RAREFACTION OF READ COUNTS
```{r}
# Load required package
library(tidyverse)

# Load the raw OTU table using full path
otu_raw <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/otu_raw_counts.csv")

# Set OTU ID column as rownames
rownames(otu_raw) <- otu_raw$SampleID
otu_raw <- otu_raw[, -1]

# Transpose to samples-as-rows
otu_t <- as.data.frame(t(otu_raw))

# Add sample ID column
otu_t <- otu_t %>%
  rownames_to_column(var = "SampleID")

# Calculate total read depth for each sample
sample_read_depths <- otu_t %>%
  mutate(Total_Reads = rowSums(across(where(is.numeric)))) %>%
  select(SampleID, Total_Reads)

# Export the result
write.csv(
  sample_read_depths,
  "/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/sample_read_depths.csv",
  row.names = FALSE
)
```

### Check for how many samples will be lost per sample group with different rarefaction thresholds

```{r}
# Load libraries
library(tidyverse)

# Load OTU table
otu <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/otu_raw_counts.csv")
rownames(otu) <- otu$SampleID
otu <- otu[, -1]

# Fix column formatting
otu <- otu %>% t() %>% as.data.frame()
otu$SampleID <- rownames(otu)

# Load metadata
metadata <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/metadata.csv")

# Merge total reads with metadata
sample_depths <- otu %>%
  rowwise() %>%
  mutate(TotalReads = sum(c_across(where(is.numeric)))) %>%
  ungroup()

# Harmonize sample IDs for joining
sample_depths$SampleID <- gsub("\\.", "-", sample_depths$SampleID)
metadata$Sample_ID <- as.character(metadata$Sample_ID)

# Merge with metadata to get Treatment info
merged <- sample_depths %>%
  left_join(metadata, by = c("SampleID" = "Sample_ID"))

# Function to count lost samples per group for a given threshold
loss_by_threshold <- function(threshold) {
  merged %>%
    mutate(Status = ifelse(TotalReads >= threshold, "Retained", "Lost")) %>%
    group_by(Treatment, Status) %>%
    summarise(Samples = n()) %>%
    pivot_wider(names_from = Status, values_from = Samples, values_fill = 0) %>%
    mutate(Threshold = threshold) %>%
    select(Threshold, everything())
}

# Try multiple thresholds
thresholds <- c(1000, 1500, 2000, 2500, 3000, 3500, 4000)

# Apply and combine
loss_table <- thresholds %>%
  map_df(loss_by_threshold)

# View
print(loss_table)
```


# Libraries
```{r}
# Load necessary libraries
library(tidyverse)
library(phyloseq)
library(vegan)
library(FSA)
library(reshape2)
library(data.table)
```


### PERFORM READ COUNT RAREFACTION AT 1500 READS FOLLOWED BY RELATIVE ABUNDANCE TRANSFORMATION
```{r}


# ------------------------------------------------------------
# 1. Load OTU table (raw read counts)
# ------------------------------------------------------------

otu_raw <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/otu_raw_counts.csv")
rownames(otu_raw) <- otu_raw$SampleID
otu_raw <- otu_raw[, -1]

# Harmonize sample IDs: replace dots with dashes
colnames(otu_raw) <- gsub("\\.", "-", colnames(otu_raw))

# Transpose to samples-as-rows format
otu_raw_t <- as.data.frame(t(otu_raw))

# ------------------------------------------------------------
# 2. Load metadata
# ------------------------------------------------------------

metadata <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Raw_Reads/metadata.csv")
rownames(metadata) <- metadata$Sample_ID
metadata <- metadata[rownames(otu_raw_t), ]

# ------------------------------------------------------------
# 3. Remove samples with zero reads and perform safety check on number of samples lost at 1500 rarefaction threshold
# ------------------------------------------------------------

sample_sums <- rowSums(otu_raw_t)
zero_samples <- names(sample_sums[sample_sums == 0])
print(zero_samples)

otu_raw_t_filtered <- otu_raw_t[sample_sums > 0, ]
metadata_filtered <- metadata[rownames(otu_raw_t_filtered), ]

# ------------------------------------------------------------
# 4. Rarefy OTU table 
# ------------------------------------------------------------

# Set rarefaction depth
rarefaction_depth <- 1500

# Rarefy full dataset directly
set.seed(42)  # For reproducibility
otu_rarefied <- rrarefy(otu_raw_t_filtered, sample = rarefaction_depth)

# Identify samples that were NOT rarefied (all 0s after rarefaction)
not_rarefied <- rownames(otu_rarefied)[rowSums(otu_rarefied) == 0]
print(not_rarefied)

# Remove unrarefied (zeroed) samples
otu_rarefied_clean <- otu_rarefied[rowSums(otu_rarefied) > 0, ]
metadata_clean <- metadata_filtered[rownames(otu_rarefied_clean), ]

# ------------------------------------------------------------
# 5. Confirm sample ID alignment after rarefaction 
# ------------------------------------------------------------

# Check matching rownames between rarefied OTU table and metadata
all(rownames(otu_rarefied) == rownames(metadata_filtered))  # should return TRUE

# ------------------------------------------------------------
# 6. Calculate alpha diversity metrics from rarefied data
# ------------------------------------------------------------

# Richness
richness <- rowSums(otu_rarefied > 0)

# Shannon diversity
shannon <- diversity(otu_rarefied, index = "shannon")

# Simpson diversity
simpson <- diversity(otu_rarefied, index = "simpson")

# Merge into metadata
metadata_alpha <- metadata_filtered %>%
  mutate(Richness = richness,
         Shannon = shannon,
         Simpson = simpson)


# ------------------------------------------------------------
# 10. Export alpha diversity metrics for Python plotting
# ------------------------------------------------------------

metadata_alpha_export <- metadata_alpha %>%
  rownames_to_column(var = "SampleID") %>%
  select(SampleID, Tree, Treatment, Richness, Shannon, Simpson)

write.csv(metadata_alpha_export, "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/alpha_diversity_normalized_for_python.csv", row.names=FALSE)

write.csv(otu_rarefied, "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/rarefied_OTU_table_1500.csv", row.names = TRUE)



```
### Linear Mixed Model with TreeID as random effect for Alpha Diversity:

```{r}
# Load necessary libraries
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)
```


```{r}


# ------------------------------------------------------------
# 1. Load rarefied alpha diversity data 
# ------------------------------------------------------------

alpha_div <- read.csv("/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/alpha_diversity_normalized_for_python.csv")

# Confirm column names
str(alpha_div)

# ------------------------------------------------------------
# 2. Fit linear mixed models for each diversity metric
# ------------------------------------------------------------

# Richness model
lmm_rich <- lmer(Richness ~ Treatment + (1|Tree), data=alpha_div)
anova_rich <- anova(lmm_rich)
summary_rich <- summary(lmm_rich)

# Shannon model
lmm_shan <- lmer(Shannon ~ Treatment + (1|Tree), data=alpha_div)
anova_shan <- anova(lmm_shan)
summary_shan <- summary(lmm_shan)

# Simpson model
lmm_simp <- lmer(Simpson ~ Treatment + (1|Tree), data=alpha_div)
anova_simp <- anova(lmm_simp)
summary_simp <- summary(lmm_simp)

# ------------------------------------------------------------
# 3. Post-hoc pairwise comparisons for treatment levels
# ------------------------------------------------------------

# Richness pairwise
emmeans_rich <- emmeans(lmm_rich, pairwise ~ Treatment, adjust="fdr")

# Shannon pairwise
emmeans_shan <- emmeans(lmm_shan, pairwise ~ Treatment, adjust="fdr")

# Simpson pairwise
emmeans_simp <- emmeans(lmm_simp, pairwise ~ Treatment, adjust="fdr")

# ------------------------------------------------------------
# 4. Export results
# ------------------------------------------------------------

# Export ANOVA tables
write.csv(as.data.frame(anova_rich), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_anova_richness.csv")
write.csv(as.data.frame(anova_shan), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_anova_shannon.csv")
write.csv(as.data.frame(anova_simp), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_anova_simpson.csv")

# Export pairwise post-hoc comparisons
write.csv(as.data.frame(emmeans_rich$contrasts), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_dunn_richness.csv")
write.csv(as.data.frame(emmeans_shan$contrasts), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_dunn_shannon.csv")
write.csv(as.data.frame(emmeans_simp$contrasts), "/Users/cbivins/Desktop/Gall_Project_Neater/Normalized_Analysis/Alpha_Diversity/LMM/LMM_dunn_simpson.csv")
```



### RE-DO BETA DIVERSITY ANALYSIS WITH TREE-ID AS RANDOM FACTOR
```{r}


# ============================================================
# 1. Load Phyloseq Object (your fully aligned object)
# ============================================================

# You already have this loaded into memory:
# galls_project_physeq_updated

# ============================================================
# 2. Transform to relative abundance 
# ============================================================

# Transform OTU table to relative abundance
galls_project_physeq_rel_abund <- transform_sample_counts(
  galls_project_physeq_updated,
  function(x) x / sum(x)
)

# Remove samples with total OTU abundance of zero
galls_project_physeq_rel_abund <- prune_samples(
  sample_sums(galls_project_physeq_rel_abund) > 0,
  galls_project_physeq_rel_abund
)

# OPTIONAL: Check the transformation (sums should all be ~1)
sample_sums(galls_project_physeq_rel_abund)

# ============================================================
# 3. Extract Sample Metadata (from RAREFIED object)
# ============================================================

meta <- as(sample_data(galls_project_physeq_rel_abund), "data.frame")
meta$SampleID <- rownames(meta)

# Extract treatment levels
treatments <- unique(meta$Treatment)

# ============================================================
# 4. Global PERMANOVA (Two-Way Model with TreeID)
# ============================================================

# Calculate Bray-Curtis distance matrix directly from rarefied object
bray_dist <- phyloseq::distance(galls_project_physeq_rel_abund, method = "bray")

# Run global PERMANOVA with full marginal model (no strata needed)
permanova_global <- adonis2(
  bray_dist ~ Tree + Treatment,
  data = meta,
  permutations = 999,
  by = "margin"
)

# View global PERMANOVA results
print(permanova_global)

# Export global PERMANOVA
write.csv(
  as.data.frame(permanova_global),
  "/Users/cbivins/Desktop/Gall_Project_Neater/Beta_Diversity/permanova_global.csv"
)

# ============================================================
# 5. Pairwise PERMANOVA (Subset-by-subset approach)
# ============================================================

pairwise_results <- data.frame()

for (i in 1:(length(treatments) - 1)) {
  for (j in (i + 1):length(treatments)) {
    
    pair <- c(treatments[i], treatments[j])
    
    # Subset phyloseq object directly
    subset_phy <- subset_samples(galls_project_physeq_rel_abund, Treatment %in% pair)
    subset_dist <- phyloseq::distance(subset_phy, method = "bray")
    subset_meta <- as(sample_data(subset_phy), "data.frame")
    
    # Run PERMANOVA with Tree nested
    adonis_res <- adonis2(
      subset_dist ~ Treatment,
      data = subset_meta,
      strata = subset_meta$Tree,
      permutations = 999,
      by = "margin"
    )
    
    # Store results
    pairwise_results <- rbind(pairwise_results, data.frame(
      Comparison = paste(pair[1], "vs", pair[2]),
      F_value = adonis_res$F[1],
      R_squared = adonis_res$R2[1],
      p_value = adonis_res$`Pr(>F)`[1]
    ))
  }
}

# Apply FDR correction to pairwise results
pairwise_results$p_adj_FDR <- p.adjust(pairwise_results$p_value, method = "BH")

# Export pairwise PERMANOVA results
write.csv(
  pairwise_results,
  "/Users/cbivins/Desktop/Gall_Project_Neater/Beta_Diversity/permanova_pairwise.csv",
  row.names = FALSE
)

# ============================================================
# 6. NMDS Export for Python Plotting
# ============================================================

set.seed(42)
nmds <- ordinate(galls_project_physeq_rel_abund, method = "NMDS", distance = "bray", k = 2)

# Extract NMDS scores
nmds_scores <- as.data.frame(scores(nmds, display = "sites"))
nmds_scores$SampleID <- rownames(nmds_scores)

# Merge with metadata
nmds_export <- inner_join(nmds_scores, meta, by = "SampleID")

# Export NMDS scores for Python plotting
write.csv(
  nmds_export,
  "/Users/cbivins/Desktop/Gall_Project_Neater/Beta_Diversity/nmds_for_python.csv",
  row.names = FALSE
)
```


### UPDATE VENN DIAGRAMS TO USE RAREFIED OTU COUNTS
```{r}
# Load necessary libraries
library(dplyr)

# === 1. Define output directory ===
output_dir <- "/Users/cbivins/Desktop/Gall_Project_Neater/Unique_OTUs/New"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# === 2. Convert rarefied OTU table to presence/absence ===
otu_pa <- otu_rarefied_clean
otu_pa[otu_pa > 0] <- 1

# === 3. Define treatment groups ===
group_names <- unique(metadata_clean$Treatment)

# Create a list of OTU matrices per group
group_otu_matrices <- lapply(group_names, function(group) {
  samples <- rownames(metadata_clean)[metadata_clean$Treatment == group]
  otu_pa[samples, , drop = FALSE]
})
names(group_otu_matrices) <- group_names

# === 4. Identify unique OTUs per group ===
get_unique_otus <- function(group_name, group_otus, all_groups) {
  other_otus <- do.call(rbind, all_groups[names(all_groups) != group_name])
  group_presence <- colSums(group_otus) > 0
  other_presence <- colSums(other_otus) > 0
  unique_otus <- names(group_presence[group_presence & !other_presence])
  return(unique_otus)
}

unique_otus_list <- lapply(names(group_otu_matrices), function(group) {
  get_unique_otus(group, group_otu_matrices[[group]], group_otu_matrices)
})
names(unique_otus_list) <- names(group_otu_matrices)

# Export unique OTU lists
for (group in names(unique_otus_list)) {
  write.csv(unique_otus_list[[group]],
            file = file.path(output_dir, paste0("unique_", group, ".csv")),
            row.names = FALSE)
}

# === 5. Identify shared OTUs for all pairwise combinations ===
group_combos <- combn(names(group_otu_matrices), 2, simplify = FALSE)
for (combo in group_combos) {
  g1 <- group_otu_matrices[[combo[1]]]
  g2 <- group_otu_matrices[[combo[2]]]
  shared <- names(which((colSums(g1) > 0) & (colSums(g2) > 0)))
  fname <- paste0("shared_", combo[1], "_and_", combo[2], ".csv")
  write.csv(shared, file = file.path(output_dir, fname), row.names = FALSE)
}

# === 6. Identify three-way overlaps for Fig 4A and Fig 4B ===
triplet_sets <- list(
  Urchin = c("Cynips_Gall", "Leaf_galled_by_Cynips", "Ungalled_leaf"),
  Saucer = c("Andricus_Gall", "Leaf_galled_by_Andricus", "Ungalled_leaf")
)

for (triplet in names(triplet_sets)) {
  sets <- group_otu_matrices[triplet_sets[[triplet]]]
  shared <- Reduce(function(x, y) (colSums(x) > 0) & (colSums(y) > 0), sets)
  shared_otus <- names(shared[shared])
  write.csv(shared_otus,
            file = file.path(output_dir, paste0("shared_", triplet, "_three_way.csv")),
            row.names = FALSE)
}
```

### ISA REDO WITH RAREFIED OTU TABLE

# Libaries
```{r}
library(indicspecies)   
library(tibble)         
library(dplyr)          
library(permute)        

```


```{r}

# --------- 1. Sanity checks ---------------------------------
stopifnot(identical(rownames(otu_rarefied_clean), rownames(metadata_clean)))
if (!is.numeric(as.matrix(otu_rarefied_clean)))
  stop("OTU table is not numeric")

# --------- 2. Optional exclusions ---------------------------
samples_to_remove <- "O1-G-5-S164-L001"          # drop if still present
otu_use  <- otu_rarefied_clean[!(rownames(otu_rarefied_clean) %in% samples_to_remove), ]
meta_use <- metadata_clean    [!(rownames(metadata_clean)     %in% samples_to_remove), ]

# --------- 3. ISA -------------------------------------------
meta_use$Treatment <- factor(meta_use$Treatment)

set.seed(42)  # reproducible permutations
indval_result <- multipatt(
  otu_use,
  meta_use$Treatment,
  func    = "IndVal.g",
  control = how(nperm = 999)
)

# --------- 4. Extract significant OTUs ----------------------
isa_significant_otus <- indval_result$sign %>%
  as.data.frame() %>%
  rownames_to_column("OTUID") %>%
  filter(p.value < 0.05)

# --------- 5. Export ----------------------------------------
outdir <- "/Users/cbivins/Desktop/Gall_Project_Neater/DSA_and_ISA"
dir.create(outdir, showWarnings = FALSE, recursive = TRUE)

write.csv(
  isa_significant_otus,
  file = file.path(outdir, "isa_significant_otus.csv"),
  row.names = FALSE
)

cat("ISA complete – results written to", file.path(outdir, "isa_significant_otus.csv"), "\n")

```
# Filter for OTUs flagged by ISA only in Andricus or Cynips galls, excluding all leaf-associated samples.

```{r}
# Define target columns (galls only)
target_cols <- c("s.Andricus_Gall", "s.Cynips_Gall")

# Define all 's.' columns
s_cols <- grep("^s\\.", colnames(isa_significant_otus), value = TRUE)

# Define non-target 's.' columns (leaf types)
other_cols <- setdiff(s_cols, target_cols)

# Filter for OTUs only in gall samples
filtered_otus <- isa_significant_otus[
  rowSums(isa_significant_otus[, target_cols]) >= 1 &
  rowSums(isa_significant_otus[, other_cols]) == 0,
]
```



### DSA Analysis 
```{r}



# Start of the code

# 1. Incorporate Pairing Information into Sample Metadata

## Extract sample data from the phyloseq object
sample_data_df <- data.frame(sample_data(galls_project_physeq_updated))

## Ensure sample names are in a column
sample_data_df$SampleID <- rownames(sample_data_df)

## a. Add PairID to Cynips samples
# Add PairID to cynips_sample_pairs
cynips_sample_pairs$PairID <- paste0("Cynips_Pair_", 1:nrow(cynips_sample_pairs))

# Reshape to long format
cynips_pairs_long <- cynips_sample_pairs %>%
  pivot_longer(cols = c(SampleName_Gall, SampleName_Leaf),
               names_to = "SampleType",
               values_to = "SampleID") %>%
  mutate(Condition = ifelse(SampleType == "SampleName_Gall", "Gall", "Galled_Leaf"))

# Merge PairID into sample_data_df
sample_data_df <- sample_data_df %>%
  left_join(cynips_pairs_long[, c("SampleID", "PairID")], by = "SampleID")

## b. Add PairID to Andricus samples
# Add PairID to andricus_sample_pairs
andricus_sample_pairs$PairID <- paste0("Andricus_Pair_", 1:nrow(andricus_sample_pairs))

# Reshape to long format
andricus_pairs_long <- andricus_sample_pairs %>%
  pivot_longer(cols = c(SampleName_Gall, SampleName_Leaf),
               names_to = "SampleType",
               values_to = "SampleID") %>%
  mutate(Condition = ifelse(SampleType == "SampleName_Gall", "Gall", "Galled_Leaf"))

# Merge PairID into sample_data_df
sample_data_df <- sample_data_df %>%
  left_join(andricus_pairs_long[, c("SampleID", "PairID")], by = "SampleID")

## c. Handle overlapping samples and fill in missing PairID and Condition
# If a sample is both in Cynips and Andricus, ensure correct PairID and Condition
# For simplicity, we'll assume there's no overlap; adjust accordingly if there is

# Set the row names of sample_data_df to the SampleID column
rownames(sample_data_df) <- sample_data_df$SampleID

# Update sample_data in the phyloseq object
# a. Rename 'Treatment' to 'Condition'
# sample_data_df <- sample_data_df %>%
# rename(Condition = Treatment)

# b. Combine 'PairID.x' and 'PairID.y' into a single 'PairID' column
# Use coalesce to handle NA values and prioritize non-NA values
sample_data_df <- sample_data_df %>%
  mutate(PairID = coalesce(PairID.x, PairID.y)) %>%
  select(-PairID.x, -PairID.y)


sample_data(galls_project_physeq_updated) <- sample_data(sample_data_df)

# 2. Subset Phyloseq Object for Each Gall Type

## a. For Cynips
# Extract sample IDs for Cynips analysis
cynips_sample_ids <- unique(c(cynips_sample_pairs$SampleName_Gall, cynips_sample_pairs$SampleName_Leaf))

# Subset phyloseq object
cynips_physeq <- prune_samples(cynips_sample_ids, galls_project_physeq_updated)

# Subset OTUs to common_cynips_otus
cynips_physeq <- prune_taxa(common_cynips_otus, cynips_physeq)

## b. For Andricus
# Extract sample IDs for Andricus analysis
andricus_sample_ids <- unique(c(andricus_sample_pairs$SampleName_Gall, andricus_sample_pairs$SampleName_Leaf))

# Subset phyloseq object
andricus_physeq <- prune_samples(andricus_sample_ids, galls_project_physeq_updated)

# Subset OTUs to common_andricus_otus
andricus_physeq <- prune_taxa(common_andricus_otus, andricus_physeq)

# 3. Prepare DESeq2 Input Data

## a. Prepare data for Cynips
# Extract count data and sample data
counts_cynips <- as(otu_table(cynips_physeq), "matrix")
sample_data_cynips <- data.frame(sample_data(cynips_physeq))

# Ensure taxa are rows
if (!taxa_are_rows(cynips_physeq)) {
  counts_cynips <- t(counts_cynips)
}

# Ensure sample names match
all(colnames(counts_cynips) == rownames(sample_data_cynips))  # Should return TRUE

## b. Prepare data for Andricus
# Extract count data and sample data
counts_andricus <- as(otu_table(andricus_physeq), "matrix")
sample_data_andricus <- data.frame(sample_data(andricus_physeq))

# Ensure taxa are rows
if (!taxa_are_rows(andricus_physeq)) {
  counts_andricus <- t(counts_andricus)
}

# Ensure sample names match
all(colnames(counts_andricus) == rownames(sample_data_andricus))  # Should return TRUE

# 4. Run DESeq2 Analysis

## a. For Cynips
# Create DESeqDataSet
dds_cynips <- DESeqDataSetFromMatrix(
  countData = counts_cynips,
  colData = sample_data_cynips,
  design = ~ PairID + Condition
)

# Filter out rows with low counts 
dds_cynips <- dds_cynips[rowSums(counts(dds_cynips)) > 1, ]

# Estimate size factors using 'poscounts' method
dds_cynips <- estimateSizeFactors(dds_cynips, type = "poscounts")


# Run DESeq2 analysis
dds_cynips <- DESeq(dds_cynips)


# Get results comparing Gall vs. Galled_Leaf
# Get results comparing Cynips_Gall vs. Leaf_galled_by_Cynips
res_cynips <- results(dds_cynips, contrast = c("Condition", "Cynips_Gall", "Leaf_galled_by_Cynips"))


## b. For Andricus
# Create DESeqDataSet
dds_andricus <- DESeqDataSetFromMatrix(
  countData = counts_andricus,
  colData = sample_data_andricus,
  design = ~ PairID + Condition
)

# Filter out rows with low counts (optional but recommended)
dds_andricus <- dds_andricus[rowSums(counts(dds_andricus)) > 1, ]

# Estimate size factors using 'poscounts' method
dds_andricus <- estimateSizeFactors(dds_andricus, type = "poscounts")

# Run DESeq2 analysis
dds_andricus <- DESeq(dds_andricus)

# Get results comparing Gall vs. Galled_Leaf
# Get results comparing Andricus_Gall vs. Leaf_galled_by_Andricus
res_andricus <- results(dds_andricus, contrast = c("Condition", "Andricus_Gall", "Leaf_galled_by_Andricus"))


# 5. Identify Significantly Increased OTUs

## a. For Cynips
# Order results by adjusted p-value
res_cynips_ordered <- res_cynips[order(res_cynips$padj), ]

# Filter for significantly increased OTUs (padj < 0.05 and log2FoldChange > 0)
sig_otus_cynips <- subset(res_cynips_ordered, padj < 0.05 & log2FoldChange > 0)

# View significant OTUs
print("Significant OTUs for Cynips:")
print(sig_otus_cynips)

## b. For Andricus
# Order results by adjusted p-value
res_andricus_ordered <- res_andricus[order(res_andricus$padj), ]

# Filter for significantly increased OTUs (padj < 0.05 and log2FoldChange > 0)
sig_otus_andricus <- subset(res_andricus_ordered, padj < 0.05 & log2FoldChange > 0)

# View significant OTUs
print("Significant OTUs for Andricus:")
print(sig_otus_andricus)

# 6. Diagnostic Plots and Result Interpretation

## a. Diagnostic plots for Cynips
# MA-Plot
plotMA(res_cynips, main = "Cynips Gall vs. Galled Leaf", ylim = c(-5, 5))

# Dispersion estimates
plotDispEsts(dds_cynips)

# Histogram of p-values
hist(res_cynips$pvalue, breaks = 50, main = "P-value Distribution for Cynips", xlab = "P-value")

## b. Diagnostic plots for Andricus
# MA-Plot
plotMA(res_andricus, main = "Andricus Gall vs. Galled Leaf", ylim = c(-5, 5))

# Dispersion estimates
plotDispEsts(dds_andricus)

# Histogram of p-values
hist(res_andricus$pvalue, breaks = 50, main = "P-value Distribution for Andricus", xlab = "P-value")

# 7. Add Taxonomy Information (if available)

## a. For Cynips
cynips_significantly_increasing_otus_df <- if (!is.null(tax_table(cynips_physeq, errorIfNULL = FALSE))) {
  taxonomy_cynips <- as.data.frame(tax_table(cynips_physeq))
  taxonomy_cynips$OTU <- rownames(taxonomy_cynips)
  sig_otus_cynips_df <- as.data.frame(sig_otus_cynips)
  sig_otus_cynips_df$OTU <- rownames(sig_otus_cynips_df)
  sig_otus_cynips_tax <- merge(sig_otus_cynips_df, taxonomy_cynips, by = "OTU")
  print("Significant OTUs for Cynips with Taxonomy:")
  print(sig_otus_cynips_tax)
}

## b. For Andricus
andricus_significantly_increasing_otus_df <- if (!is.null(tax_table(andricus_physeq, errorIfNULL = FALSE))) {
  taxonomy_andricus <- as.data.frame(tax_table(andricus_physeq))
  taxonomy_andricus$OTU <- rownames(taxonomy_andricus)
  sig_otus_andricus_df <- as.data.frame(sig_otus_andricus)
  sig_otus_andricus_df$OTU <- rownames(sig_otus_andricus_df)
  sig_otus_andricus_tax <- merge(sig_otus_andricus_df, taxonomy_andricus, by = "OTU")
  print("Significant OTUs for Andricus with Taxonomy:")
  print(sig_otus_andricus_tax)
}

```



### Export dataframes 

```{r}

# Define the path to the directory
output_dir <- "/Users/christopherbivins/Desktop/csv_files_for_galls_graphs/Log2Fold_Increases/"

# Export each dataframe as a CSV file
write.csv(isa_significant_otus, file = paste0(output_dir, "isa_significant_otus.csv"), row.names = FALSE)
write.csv(cynips_significantly_increasing_otus_df, file = paste0(output_dir, "cynips_significantly_increasing_otus_df.csv"), row.names = FALSE)
write.csv(andricus_significantly_increasing_otus_df, file = paste0(output_dir, "andricus_significantly_increasing_otus_df.csv"), row.names = FALSE)

```

